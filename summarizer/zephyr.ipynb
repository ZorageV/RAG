{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Zorage\\ML\\Projects\\RAG\\ragllm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.huggingface import HuggingFaceInferenceAPI  \n",
    "from llama_index.core import Settings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.llms.llama_cpp.llama_utils import messages_to_prompt,completion_to_prompt\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]  = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./pdfs/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"I'm providing you with a research paper your job is to summarizes the information within it.\"\n",
    "\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"Your job is to summarize different sections of the document given to you.\"\n",
    "    \"Write a response that appropriately completes the request given to you.\\n\\n\"\n",
    "    \"### Instruction:\\n{query_str}\\n\\n### Response:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceInferenceAPI(model_name=\"HuggingFaceH4/zephyr-7b-alpha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = LangchainEmbedding(\n",
    "  HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=5,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\").get_nodes_from_documents(documents)\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=128,chunk_overlap=20)\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      " \n",
      "\n",
      "The paper presents the Inception architecture, a new approach to deep neural networks that aims to\n",
      "reduce the computational cost while maintaining or improving the accuracy. The architecture is based\n",
      "on the concept of inception modules, which are designed to perform computations at multiple scales\n",
      "simultaneously. The paper also introduces the GoogLeNet model, which is a particular implementation\n",
      "of the Inception architecture used in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC)\n",
      "2014. The model achieved state-of-the-art results with a computational budget of 1.5 billion multiply-\n",
      "adds at inference time. The paper also discusses the use of ensemble prediction and other techniques\n",
      "during testing to obtain higher performance. The results show a significant improvement in accuracy\n",
      "compared to the previous edition of the detection task, with all top performing teams using Convolutional\n",
      "Networks. The paper also provides a comparison with other approaches and discusses the practical\n",
      "usefulness of the design.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=20,\n",
    "    verbose=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    node_postprocessor=[MetadataReplacementPostProcessor(\"window\")])\n",
    "response = query_engine.query(\"Generate a summary about the paper like abstract, methodology and results and output them.\")\n",
    "print(F\"Response: \\n {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
